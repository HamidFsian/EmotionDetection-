{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0cb9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#author_Hamid_Fsian\n",
    "#Emotion Detection using Faces\n",
    "#this script is basically to load my database and train my model,\n",
    "#the i will upload my model into my machine in order to use OpenCV and make it\n",
    "#run in real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c017c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "#ML libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from keras.preprocessing.image import load_img, img_to_array #to load image and make them an array\n",
    "from keras.preprocessing.image import ImageDataGenerator #generate image from a path\n",
    "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
    "from keras.models import Model,Sequential\n",
    "#from keras.optimizers import Adam,SGD,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_size = 48 #standard our pic to 48by48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_size = 48\n",
    "path_train = \"drive/MyDrive/FaceEmotion/NewFolder/train/\" #the path for my training data\n",
    "path_validation = \"drive/MyDrive/FaceEmotion/NewFolder/validation/\" #path for my validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98179389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from google.colab.patches import cv2_imshow\n",
    "from skimage import io\n",
    "#this code is here just to check if my iamges are loaded correctly\n",
    "path = \"drive/MyDrive/FaceEmotion/NewFolder/train/angry/0.jpg\"\n",
    "image = io.imread(path,plugin='matplotlib')\n",
    "image = np.array(image, dtype=np.uint8)\n",
    "print(image.shape)\n",
    "#gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "cv2_imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size  = 32 #number of training exemples that my model will see in 1 iteration\n",
    "#2^n better use this type of batch size\n",
    "datagen_train  = ImageDataGenerator() #generate image for the training part\n",
    "datagen_val = ImageDataGenerator() #same thing for validation data\n",
    "\n",
    "#train_set va contenir le datagen_train qui lui à travers(flow_from_directory) ira chercher ce dossier du path train\n",
    "#greyscale parce que c'est en lvl grey\n",
    "#categorical because i have 7 classes\n",
    "#shuffle pour melanger\n",
    "#NB : we don't need to shuffle the validation pack\n",
    "train_set = datagen_train.flow_from_directory(path_train,\n",
    "                                              target_size = (picture_size,picture_size),\n",
    "                                              color_mode = \"grayscale\",\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True)\n",
    "test_set = datagen_val.flow_from_directory(path_validation,\n",
    "                                              target_size = (picture_size,picture_size),\n",
    "                                              color_mode = \"grayscale\",\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=False)\n",
    "#Found 28831 images belonging to 7 classes.\n",
    "#Found 7066 images belonging to 7 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f863cb",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Building the network\n",
    "no_of_classes = 7 #because i have 7 classes\n",
    "\n",
    "model = Sequential() \n",
    "\n",
    "#1st CNN layer\n",
    "model.add(Conv2D(32,(3,3),padding = 'same',input_shape = (48,48,1))) #nombre de filtres, apres taille 48,48,1 psk c'est notre taille 1psk greyscale\n",
    "model.add(BatchNormalization()) #normaliser mes data automatiquement\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))#desactiver aleatoirement des neuronnes(25%) pour eviter que mon modéle ne soit dependant de mes data base\n",
    "\n",
    "#2nd CNN layer\n",
    "model.add(Conv2D(64,(5,5),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#3rd CNN layer\n",
    "model.add(Conv2D(128,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#4th CNN layer\n",
    "model.add(Conv2D(128,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) #pour les mettres dans un vecteur\n",
    "\n",
    "\n",
    "#Fully connected Layers\n",
    "#FC 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# FC layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(no_of_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001) \n",
    "\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy']) #CatCross... parceque j'ai plusieurs classes \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#most intresting part\n",
    "#EarlyStopping : in order to stop my model from computing if the accuracy stagnate. and avoid overfiting\n",
    "#ReduceLRonPlateau : in order to reduce the learning rate when one iteration is complete and become quicker\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping , ReduceLROnPlateau \n",
    "checkpoint = ModelCheckpoint(\"./modelProf.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#modelchekpoint is used pour enregistrer ton model en ou paramétres dans un chekpoint file (generalement avec model.fit)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=3,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )#si ma precision n'augmente pas, alors on arréte et on évite le overfitting\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n",
    "\n",
    "epochs = 48\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit_generator(generator=train_set,\n",
    "                                steps_per_epoch=train_set.n//train_set.batch_size,\n",
    "                                epochs=epochs,\n",
    "                                validation_data = test_set,\n",
    "                                validation_steps = test_set.n//test_set.batch_size,\n",
    "                                callbacks=callbacks_list\n",
    "                                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

